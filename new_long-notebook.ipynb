{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying a new approach to the feature selection, mainly using feature importance scores for different models.  \n",
    "Will run some pipelines for different models, for each of them select some features and do some hyperparameter tuning - then I can combine them using stacking (and each model can use different features!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "import data_preprocess as dp # data_preprocess.py\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training data with all the features\n",
    "data = dp.data_preprocess(one_hot_location=True)\n",
    "\n",
    "features = ['absolute_humidity_2m:gm3',\n",
    "       'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J',\n",
    "       'clear_sky_rad:W', 'cloud_base_agl:m', 'dew_or_rime:idx',\n",
    "       'dew_point_2m:K', 'diffuse_rad:W', 'diffuse_rad_1h:J', 'direct_rad:W',\n",
    "       'direct_rad_1h:J', 'effective_cloud_cover:p', 'elevation:m',\n",
    "       'fresh_snow_12h:cm', 'fresh_snow_1h:cm', 'fresh_snow_24h:cm',\n",
    "       'fresh_snow_3h:cm', 'fresh_snow_6h:cm', 'is_day:idx',\n",
    "       'is_in_shadow:idx', 'msl_pressure:hPa', 'precip_5min:mm',\n",
    "       'precip_type_5min:idx', 'pressure_100m:hPa', 'pressure_50m:hPa',\n",
    "       'prob_rime:p', 'rain_water:kgm2', 'relative_humidity_1000hPa:p',\n",
    "       'sfc_pressure:hPa', 'snow_density:kgm3', 'snow_depth:cm',\n",
    "       'snow_drift:idx', 'snow_melt_10min:mm', 'snow_water:kgm2',\n",
    "       'sun_azimuth:d', 'sun_elevation:d', 'super_cooled_liquid_water:kgm2',\n",
    "       't_1000hPa:K', 'total_cloud_cover:p', 'visibility:m',\n",
    "       'wind_speed_10m:ms', 'wind_speed_u_10m:ms', 'wind_speed_v_10m:ms',\n",
    "       'wind_speed_w_1000hPa:ms', 'A', 'B', 'C', 'time']\n",
    "\n",
    "X_train, targets = dp.get_training_data(data, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the different types of features (categorical, one-hot, and numerical)\n",
    "cat_cols = ['is_day:idx', 'is_in_shadow:idx','month', 'hour', 'day']\n",
    "\n",
    "one_hot_cols = ['A', 'B', 'C']\n",
    "\n",
    "num_cols = ['absolute_humidity_2m:gm3',\n",
    "       'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J',\n",
    "       'clear_sky_rad:W', 'cloud_base_agl:m', 'dew_or_rime:idx',\n",
    "       'dew_point_2m:K', 'diffuse_rad:W', 'diffuse_rad_1h:J', 'direct_rad:W',\n",
    "       'direct_rad_1h:J', 'effective_cloud_cover:p', 'elevation:m',\n",
    "       'fresh_snow_12h:cm', 'fresh_snow_1h:cm', 'fresh_snow_24h:cm',\n",
    "       'fresh_snow_3h:cm', 'fresh_snow_6h:cm','msl_pressure:hPa', 'precip_5min:mm',\n",
    "       'precip_type_5min:idx', 'pressure_100m:hPa', 'pressure_50m:hPa',\n",
    "       'prob_rime:p', 'rain_water:kgm2', 'relative_humidity_1000hPa:p',\n",
    "       'sfc_pressure:hPa', 'snow_density:kgm3', 'snow_depth:cm',\n",
    "       'snow_drift:idx', 'snow_melt_10min:mm', 'snow_water:kgm2',\n",
    "       'sun_azimuth:d', 'sun_elevation:d', 'super_cooled_liquid_water:kgm2',\n",
    "       't_1000hPa:K', 'total_cloud_cover:p', 'visibility:m',\n",
    "       'wind_speed_10m:ms', 'wind_speed_u_10m:ms', 'wind_speed_v_10m:ms',\n",
    "       'wind_speed_w_1000hPa:ms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor, StackingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_trans = ColumnTransformer(\n",
    "    [('categories', OneHotEncoder(dtype='int'), cat_cols),\n",
    "     ('numerical', MinMaxScaler(), num_cols),\n",
    "     ('one_hot_allready', 'passthrough', one_hot_cols),],\n",
    "     remainder='drop', verbose_feature_names_out=True)\n",
    "\n",
    "class TimeFeatureAdder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Adds the features month and hour to the data\"\"\"\n",
    "\n",
    "    def __init__(self, add_features=True):\n",
    "        self.add_features = add_features\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "\n",
    "        X_copy = X.copy()\n",
    "\n",
    "        timestamps = X[\"time\"]\n",
    "        month = timestamps.apply(lambda x: x.month)\n",
    "        hour = timestamps.apply(lambda x: x.hour)\n",
    "        day = timestamps.apply(lambda x: x.day)\n",
    "\n",
    "        if self.add_features:\n",
    "            X_copy[\"month\"] = month\n",
    "            X_copy[\"hour\"] = hour\n",
    "            X_copy[\"day\"] = day\n",
    "            return X_copy\n",
    "        else:\n",
    "            return X_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_process_pipeline = Pipeline([\n",
    "    ('add_features', TimeFeatureAdder()),\n",
    "    ('column_transform', column_trans),\n",
    "    ('imputer', SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0)),\n",
    "])\n",
    "\n",
    "random_forest_pipeline = Pipeline([\n",
    "    ('data_process', data_process_pipeline),\n",
    "    ('random_forest', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "grad_boost_pipeline = Pipeline([\n",
    "    ('data_process', data_process_pipeline),\n",
    "    ('grad_boost', GradientBoostingRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "sgd_regressor_pipeline = Pipeline([\n",
    "    ('data_process', data_process_pipeline),\n",
    "    ('grad_boost', SGDRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "svr_regressor_pipeline = Pipeline([\n",
    "    ('data_process', data_process_pipeline),\n",
    "    ('grad_boost', SVR())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import mean_squared_error\n",
    "\n",
    "random_forest_pipeline.fit(X_train, targets)\n",
    "train_predictions = random_forest_pipeline.predict(X_train)\n",
    "mean_squared_error(train_predictions, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# get the rf model from the pipeline\n",
    "random_forest_model = random_forest_pipeline.named_steps['random_forest']\n",
    "\n",
    "# get the column transformer and feature names\n",
    "preprocessor = data_process_pipeline.named_steps['column_transform']\n",
    "feature_names_after_encoding = preprocessor.named_transformers_['categories'].get_feature_names_out()\n",
    "all_feature_names = list(X_train.columns) + list(feature_names_after_encoding)\n",
    "\n",
    "# get the feature importance\n",
    "feature_importances = random_forest_model.feature_importances_\n",
    "\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': all_feature_names,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat_cols) + len(one_hot_cols) + len(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.50547221e-07, 2.05535855e-07, 1.94338500e-04, 9.60739821e-05,\n",
       "       2.19957262e-05, 5.27315333e-04, 2.15676180e-04, 2.68515560e-04,\n",
       "       3.40682690e-04, 3.84149165e-04, 4.93846579e-04, 6.84295144e-04,\n",
       "       2.42054366e-04, 1.92463078e-04, 1.17250395e-04, 4.49485817e-06,\n",
       "       1.09420265e-07, 3.28872278e-07, 6.57594462e-07, 3.88019754e-06,\n",
       "       2.20252053e-05, 1.01493097e-04, 1.14143332e-04, 2.73186118e-04,\n",
       "       6.41975735e-04, 5.76849495e-04, 5.23582884e-04, 3.83122212e-04,\n",
       "       2.61766650e-04, 3.27226672e-04, 2.27468605e-04, 1.05161894e-04,\n",
       "       1.11226550e-04, 1.95835743e-05, 1.44925183e-05, 1.07054191e-06,\n",
       "       6.24202573e-07, 5.85902383e-07, 2.53556687e-07, 2.51028764e-07,\n",
       "       6.11106919e-04, 2.56970697e-04, 2.47056751e-04, 3.57943827e-04,\n",
       "       2.42068615e-04, 7.65304747e-04, 4.52422432e-04, 3.22236474e-04,\n",
       "       4.56187494e-04, 2.10305959e-04, 2.87497633e-04, 2.15120174e-04,\n",
       "       3.30742187e-04, 2.93685024e-04, 3.02439549e-04, 5.30187024e-04,\n",
       "       1.56563992e-04, 2.68764901e-04, 5.64559983e-04, 3.06479838e-04,\n",
       "       3.11309333e-04, 2.10500712e-04, 3.22030752e-04, 2.21440162e-04,\n",
       "       3.11490326e-04, 4.61991998e-04, 4.47137737e-04, 3.24306550e-04,\n",
       "       2.21507708e-04, 2.29333203e-04, 1.64325337e-04, 3.13653033e-03,\n",
       "       4.90690600e-03, 4.66238891e-03, 4.43782162e-03, 9.44493082e-03,\n",
       "       5.87952701e-03, 2.36800960e-06, 4.29566124e-03, 6.27764804e-02,\n",
       "       5.12666490e-03, 3.87840573e-01, 6.40889968e-03, 5.72803620e-03,\n",
       "       2.08822699e-01, 6.90381914e-05, 1.80570002e-06, 7.83868536e-04,\n",
       "       3.81630716e-06, 4.25083117e-05, 3.03412532e-03, 8.89749933e-04,\n",
       "       4.47389384e-04, 3.05361082e-03, 2.53601598e-03, 3.02520247e-06,\n",
       "       3.25954870e-04, 4.75727525e-03, 2.79109575e-03, 0.00000000e+00,\n",
       "       5.61812831e-05, 0.00000000e+00, 1.48600706e-05, 1.01355350e-03,\n",
       "       3.76632889e-02, 1.08649950e-02, 1.09711140e-03, 5.46622540e-03,\n",
       "       5.36088906e-03, 6.03280359e-03, 5.79119216e-03, 7.70394868e-03,\n",
       "       6.34158601e-03, 2.69798991e-06, 1.62295595e-01, 1.20868179e-04,\n",
       "       6.75462870e-05])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRADIENT BOOSTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STOCHASTIC GRADIENT DESCENT REGRESSOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SUPPORT VECTOR MACHINE REGRESSOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
