{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Taheera Ahmed\\code\\tdt4173-project\\tdt4173-project\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from utils.read_data import get_train_targets, load_data, get_test_data, prepare_submission\n",
    "from utils.generate_run_name import generate_run_name\n",
    "import numpy as np\n",
    "import logging\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import catboost as cb\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from autogluon.tabular import TabularPredictor\n",
    "import logging\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, RegressorMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['time', 'elevation:m', 'fresh_snow_1h:cm', 'ceiling_height_agl:m', 'snow_density:kgm3', \n",
    "             'wind_speed_w_1000hPa:ms', 'snow_drift:idx', 'fresh_snow_3h:cm', 'is_in_shadow:idx', 'dew_or_rime:idx', 'fresh_snow_6h:cm', 'prob_rime:p'] # this second line is columns with feature importance == 0\n",
    "\n",
    "data_a, data_b, data_c = load_data(mean=True, remove_out=True, roll_avg=True, cust_feat=True, drop_cols=drop_cols, cycle_encoding = True)\n",
    "X_test_a, X_test_b, X_test_c = get_test_data(mean=True, roll_avg=True, cust_feat=True, cycle_encoding = True)\n",
    "\n",
    "# Assuming get_train_targets is defined and returns the features and target\n",
    "X_train_a, y_a = get_train_targets(data_a)\n",
    "X_train_b, y_b = get_train_targets(data_b)\n",
    "X_train_c, y_c = get_train_targets(data_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoGluonWrapper(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.model = TabularPredictor.load(path)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # AutoGluon's fit method is called during the initial training, \n",
    "        # so we don't need to call it here again.\n",
    "        # Just return self to adhere to scikit-learn's fit method requirements.\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you can add your AutoGluon model to the base models\n",
    "autogluon_model_a = AutoGluonWrapper(\"C:\\\\Users\\\\Taheera Ahmed\\\\code\\\\tdt4173-project\\\\autogluon\\\\Bolk Cubi-A\")\n",
    "\n",
    "\"\"\"\n",
    "cat_boost1: bayesian_search on params given feat_eng from 07.nov\n",
    "cat_boost2: from best kaggle submission\n",
    "\"\"\"\n",
    "base_model_a = [\n",
    "    ('autogluon', autogluon_model_a),\n",
    "    ('cat_boost3', cb.CatBoostRegressor(random_state=42, silent=True)),\n",
    "]\n",
    "# Define meta-learners for each location\n",
    "meta_learner_a = LinearRegression()\n",
    "\n",
    "    # Create the stacking regressor for the current location\n",
    "stacked_model = StackingRegressor(estimators=base_model_a, final_estimator=meta_learner_a)\n",
    "\n",
    "# Create the whole model pipeline for the current location\n",
    "whole_model_pipeline = Pipeline([\n",
    "    ('stacked_model', stacked_model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_model_pipeline.fit(X_train_a, y_a)\n",
    "predictions = whole_model_pipeline.predict(X_test_a.drop(columns=[\"id\", \"prediction\", \"location\"]))\n",
    "\n",
    "# Prepare submission using the predictions\n",
    "prepare_submission(X_test_a, predictions, run_name=run_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tdt4173-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
